---
title: "John Schulman (OpenAI Cofounder) - Reasoning, RLHF, & Plan for 2027 AGI"
date: "2024-05-15"
tags: [Tech, Innovation, AI]
---

## The Future of AI: A Conversation with John Schulman 

In a fascinating conversation with John Schulman, co-founder of OpenAI and lead of the post-training team behind ChatGPT, we delve into the exciting world of artificial intelligence and its potential trajectory over the coming years. 

### Pretraining vs. Post-training: Building the Foundation and Shaping the Personality of AI

The discussion begins by unraveling the distinction between pretraining and post-training in AI models. Schulman explains that pretraining involves immersing the model in vast amounts of data from the internet, allowing it to mimic the diverse styles and content it encounters:

* **Pretraining creates a foundation of knowledge and understanding:** By training on websites, code, and diverse text formats, the AI gains a broad grasp of language and the world.
* **Post-training focuses on specific behaviors and tasks:** This stage shapes the AI's "personality" and refines its ability to perform desired tasks, such as coding or acting as a helpful chat assistant. 

### From Chatbots to Complex Projects: The Next Five Years

Schulman predicts significant advancements in AI capabilities over the next five years, even suggesting that they could undertake more involved tasks like:

* **Carrying out entire coding projects:** Moving beyond single suggestions, AI could potentially handle larger coding assignments, including writing multiple files and testing the output.
* **Increased coherence and understanding:** AI's ability to act coherently for extended periods will unlock the potential for more complex tasks, mimicking human workflows.

Schulman emphasizes that this progress will come from a combination of factors, including training on more challenging tasks, improving error recovery mechanisms, and increasing sample efficiency, meaning the models require less data to learn.

### The Looming Possibility of AGI: Careful Steps and the Need for Coordination

The conversation explores the possibility of Artificial General Intelligence (AGI) arising sooner than expected. While Schulman acknowledges the potential for a discontinuous jump in capabilities, he stresses the importance of careful deployment and coordination among key players in the AI field:

* **AGI demands responsible development:** Schulman emphasizes OpenAI's commitment to cautious deployment, potentially involving slowing down training and deployment until safety concerns are addressed. 
* **Collaboration is key to avoiding a "race dynamic":** Schulman sees a need for agreement among major AI developers on reasonable limits for deployment and training to prioritize safety and responsible development. 

### The Evolution of RLHF and the Challenge of Aligning AI with Human Values

Schulman delves into Reinforcement Learning from Human Feedback (RLHF), the method employed to train AI models to align with human preferences. 

* **Reward models provide a glimpse into human desires:** They act as an aggregate representation of what people want, helping to guide the AI towards helpful and useful behavior. 
* **The future of RLHF:** Schulman anticipates a need to refine RLHF as AI models become more powerful, exploring alternative approaches to capturing and aligning with subtle human preferences and values. 

### The Future Landscape: AI Assistants as Extensions of Human Will 

Schulman paints a picture of a future where AI assistants are deeply integrated into our workflows, acting as helpful colleagues that can:

* **Handle complex projects with longer time horizons:** AI will move beyond one-off queries and engage in longer-term projects, understanding the entire context of a user's work. 
* **Proactively suggest solutions and perform tasks in the background:** AI will become more active collaborators, anticipating user needs and autonomously contributing to project progress.

Schulman emphasizes OpenAI's goal of creating AI that acts as an extension of people's will, following instructions and assisting users while prioritizing safety and avoiding paternalistic control. 

**Key Quote:** 

> "I hope the form factor would basically be that people are still driving all this and you have your uh like helpful assistants that you can use you can sort of direct and point to lots of different problems that are useful to you and everyone sort of has all these uh AIs uh helping them uh helping them do more, get more done." - **John Schulman**

This conversation reveals a fascinating glimpse into the potential future of AI, highlighting the exciting possibilities as well as the critical need for responsible development and alignment with human values.

---

<a href="https://youtube.com/watch?v=Wo95ob_s_NI" target="_blank">Watch the podcast here!</a>


---

**Read another blog about [Bastian Lehmann: How the Uber Deal Went Down and How a $2.65BN Deal Turned into $5BN | E1137](./20240408-bastilehmann-20vcwithharrystebbings)**